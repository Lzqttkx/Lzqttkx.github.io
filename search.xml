<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2023/02/17/unfaircoin/"/>
      <url>/2023/02/17/unfaircoin/</url>
      
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">---title: 连续抛硬币问题date: 2023-02-17 00:18:40author: 李哲祺top: falsehide: falsetoc: truemathjax: truecategories: machine learningtags:  - machine learning  - Maximum Likelihood  - Bayesian Approach---<h1 id="一枚不公平的硬币–最大似然估计和贝叶斯方法"><a href="#一枚不公平的硬币–最大似然估计和贝叶斯方法" class="headerlink" title="一枚不公平的硬币–最大似然估计和贝叶斯方法"></a><strong>一枚不公平的硬币–最大似然估计和贝叶斯方法</strong></h1><h2 id="问题介绍"><a href="#问题介绍" class="headerlink" title="问题介绍"></a>问题介绍</h2><p>想象一下，我们正在进行一个预测连续抛硬币的过程。我们可以使用伯努利过程来建模。在伯努利过程中，一个随机变量有两种可能的结果: {0,1} (我们可以把0看作是 “正面” 而把1看成是 “反面”。如果我们抛出一枚硬币，我们可以将抛出结果的概率建模成为:</p><p>$$<br>𝑃（𝑥&#x3D;1）&#x3D; \mu<br>$$</p><p>同时，当𝑃(𝑥&#x3D;0):</p><p>$$<br>𝑃(𝑥&#x3D;0)&#x3D;1-𝑃(𝑥&#x3D;1)<br>$$</p><p>如果$\mu$&#x3D;0.5，这说明抛硬币是公平的。当我们抛出$𝑁$&#x3D;100次时，我们可能会得到一个包含正面和反面结果的序列。由于每次抛出的单个元素是不可预测的，但我们可以估计大约有50个正面和50个反面。如果我们看到25个正面和75个反面，我们就很难相信$\mu$&#x3D;0.5而可能猜测它更接近于$\mu$&#x3D;0.75。</p><h2 id="具体问题"><a href="#具体问题" class="headerlink" title="具体问题"></a>具体问题</h2><p>假设我们现在已有的信息是：$\mu$有五个可能的值：0, 0.25, 0.5, 0.75, 1.0。并且我们得到了有限次数下投掷硬币的观察结果，将其表示为$𝑁$。在这些观察的基础上，我们需要对未来继续抛掷硬币可能产生的序列进行建模。我们将使用两种方法：最大似然估计法和贝叶斯法。</p><h3 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h3><p>首先，我们记下我们连续抛硬币后观察到的一系列结果，并写下该特定投掷序列的概率作为$\mu$的函数。我们可以这样做的原因是，我们已经根据𝑃(𝑥&#x3D;1∣$\mu$)&#x3D;$\mu$；𝑃(𝑥&#x3D;0∣$\mu$)&#x3D;1-𝑃(𝑥&#x3D;1∣$\mu$) 得到了单个结果的概率，并且每次单次抛硬币的结果是独立的。因此我们可以将单个抛掷结果的概率相乘来得出一系列的概率。</p><p>当连续抛掷硬币序列的$𝑁$&#x3D;5时，如果我们假设，第一次抛掷的结果是1，其他四次是0：<br>$$<br>10000<br>$$<br>那么，这个特定结果的概率是:<br>$$<br>\mu(1-\mu)^4<br>$$<br>当结果序列为:<br>$$<br>01000<br>$$<br>概率同理可得也是:<br>$$<br>\mu(1-\mu)^4<br>$$<br>不难看出，对于观察到的$N$次抛掷的序列，其中如果观察到抛掷结果为”1”的数量为$N_1$，那么抛掷结果是”0”的数量就为<br>$N_0 &#x3D; N - N_1$<br>，这些结果的概率是（无论1和0是以什么顺序出现的）:</p><p>$$<br>\lambda &#x3D; \mu^{N_{1}}(1- \mu)^{N-N_1},<br>$$</p><p>在最大似然估计法中，我们将上述表达式视为一种似然。在这个函数中只有一个参数，那就是$\mu$。而我们的目标是找到$\mu$的值，使$\lambda$的值达到最大。为了方便进行计算，我们通常将其转化为使用log的形式:<br>$$<br>\ln N &#x3D; N_1 \ln \mu + (N - N_1) \ln (1 - \mu)<br>$$<br>当$\lambda$的值取到最大时，即使得$\ln \lambda$的值取到最小。所以，我们将它求导后的值取到0时来求达到该最小值时的$\mu$的值。<br>$$<br>\frac{N_1}{\mu} - \frac{(N - N_1)}{1 - \mu} &#x3D; 0<br>$$<br>继续推得:<br>$$<br>N_1(1 - \mu) &#x3D; (N - N_1) \mu<br>$$<br>最终可得:<br>\begin{equation}<br>\mu &#x3D; \frac{N_1}{N}<br>\end{equation}</p><p>将上式进行二次求导可得：<br>$$<br>-\frac{N_1}{\mu^2} - \frac{(N - N_1)}{(1 - \mu)^2}<br>$$<br>由于$N - N_1 &gt; 0$ 并且 $N &gt;0$， 因此得到的这个结果为负。从而我们可以推出$\mu &#x3D; \frac{N_1}{N}$，是这个对数似然估计的最小值，并且是唯一的最小值。因此，$\mu$取这个值时得到最大的似然估计值。</p><p>直观地说，这个对$\mu$取值的估计是有意义的。</p><h3 id="贝叶斯方法"><a href="#贝叶斯方法" class="headerlink" title="贝叶斯方法"></a>贝叶斯方法</h3><p>贝叶斯方法要求我们对$\mu$的先验值做出假设。在贝叶斯的观点中，概率与个人主观的相信程度相对应。首先我们先假设认为$\mu$取到五个值，我们必须对这些值定义一个概率分布，这个分布即为先验分布。例如，我们可以先假设:</p><p>$$<br>\begin{align}<br>P_{prior}(\mu &#x3D; 0. )   &amp; &#x3D; 0.05 \\<br>P_{prior}(\mu &#x3D; 0.25)  &amp; &#x3D; 0.05 \\<br>P_{prior}(\mu &#x3D; 0.50 ) &amp; &#x3D; 0.7 \\<br>P_{prior}(\mu &#x3D; 0.75 ) &amp; &#x3D; 0.15 \\<br>P_{prior}(\mu &#x3D; 1.0 )  &amp; &#x3D; 0.05<br>\end{align}<br>$$</p><p>我们的目标是根据我们所观察到的一连串抛掷硬币的情况来重新评估这些概率。通过贝叶斯法则，我们可以得到:<br>$$<br>P(\mu \mid D ) &#x3D; \frac{P(D \mid \mu)}{P(D)} P_{prior}(\mu)<br>$$<br>这里$P(D \mid \mu)$是上面所假设的数据的可能性:<br>$$<br>P(D \mid \mu) &#x3D; \mu^{N_1}(1 - \mu)^{N - N_1},<br>$$<br>鉴于$\mu$它已经给出了一个特定序列的概率，它可以被归纳为唯一的两个相关数字:抛掷结果为0的数量$N_0$,和结果为1的数量$N_1$。其总数为$N&#x3D; N_0 + N_1$。<br>通过对一系列的连续投掷结果观察，我们可以有统计的数字结果来计算后验概率$P(\mu \mid D)$。</p><h4 id="归一化的复杂性"><a href="#归一化的复杂性" class="headerlink" title="归一化的复杂性"></a>归一化的复杂性</h4><p>通过归一化系数计算一个单一的$\mu$的后验概率是比较简单的:<br>$$<br>P_{posterior}(\mu &#x3D; 0.5) \sim P( D \mid \mu)P_{prior}(\mu &#x3D; 0.5)<br>$$<br>考虑到可能性的简单形式和我们知道先验概率的情况，这是一个轻量级的计算。但是为了正确地归一化，我们需要直接计算$\sum_\mu P(D \mid \mu)P(\mu)$或者估计所有可能结果的后验概率，并使用它来归一化后验分布。</p><p>在后文中会具体演示这两种方法。无论是哪种方式，要计算一个结果的后验概率，我们都必须计算所有的结果。即使在这样一个小表格上，仅仅计算一个整体的归一化系数就需要很大量的工作。特别是对于大量的结果和多变量似然分布，这个问题可能变得很严重。但是通过使用参数化分布，如高斯分布，有时候可以避免这个问题。后文将更详细地讨论这个问题。</p><h3 id="例一："><a href="#例一：" class="headerlink" title="例一："></a>例一：</h3><p>已有大量的$\mu &#x3D; 0.75$的观测值。计算最大似然估计和后验分布。</p><h4 id="数据样本"><a href="#数据样本" class="headerlink" title="数据样本"></a>数据样本</h4><p>我们使用二项分布$N &#x3D;1$， $p &#x3D; 0.75$来生成 $\mbox{Ber}( x \mid \mu &#x3D; 0.75)$的100个观察值的样本。</p><h4 id="最大似然估计-1"><a href="#最大似然估计-1" class="headerlink" title="最大似然估计"></a>最大似然估计</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'figure.figsize'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'figure.dpi'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">200</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> numpy<span class="token punctuation">.</span>random <span class="token keyword">import</span> default_rngrng <span class="token operator">=</span> default_rng<span class="token punctuation">(</span><span class="token punctuation">)</span>N_bin  <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># binomial for N=1 is Bernouilli</span>p    <span class="token operator">=</span> <span class="token number">0.75</span>size <span class="token operator">=</span> <span class="token number">100</span>sample <span class="token operator">=</span> rng<span class="token punctuation">.</span>binomial<span class="token punctuation">(</span>N_bin<span class="token punctuation">,</span> p<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>sample<span class="token punctuation">)</span>n_ones <span class="token operator">=</span> sample<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># the sum is adequate for a total count</span>mu_ml <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>n_ones<span class="token punctuation">)</span><span class="token operator">/</span>size<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'mu_ml = '</span><span class="token punctuation">,</span> mu_ml<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果为：<br>[1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1<br> 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0<br> 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1]<br>mu_ml &#x3D;  0.71</p><h5 id="提示"><a href="#提示" class="headerlink" title="提示"></a>提示</h5><ul><li>这是对原来$\mu$的合理估计。重要的是建模者只看到数据，而不能看到如何生成数据。为了执行预测，建模者将使用类似的代码(他们并不知道示例是如何创建的)，他们使用$p &#x3D; \mu_{ml}$</li><li>这是$\mu$的估计值。重复单元格将在结果中提供更多的信息。</li><li>用真实数据做的实验往往不能随意重复。在这种情况下，最大似然估计仍然是一个点估计。</li></ul><h4 id="后验分布"><a href="#后验分布" class="headerlink" title="后验分布"></a>后验分布</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltmu_values <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">0.25</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.75</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>prior   <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span>   <span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">0.15</span><span class="token punctuation">,</span>  <span class="token number">0.05</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'If the prior is a proper probability distribution function, it should be normalised:'</span><span class="token punctuation">,</span> prior<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># we use the same sample as generated above that was used for the ML estimate</span>ones  <span class="token operator">=</span> n_oneszeros <span class="token operator">=</span> size <span class="token operator">-</span> ones<span class="token keyword">def</span> <span class="token function">likelihood</span><span class="token punctuation">(</span>mu<span class="token punctuation">,</span> ones<span class="token punctuation">,</span> zeros<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># multiply performs element wise multiplication</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>mu<span class="token punctuation">,</span>ones<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>mu<span class="token punctuation">,</span>zeros<span class="token punctuation">)</span><span class="token punctuation">)</span>llh <span class="token operator">=</span> likelihood<span class="token punctuation">(</span>mu_values<span class="token punctuation">,</span>ones<span class="token punctuation">,</span>zeros<span class="token punctuation">)</span>posterior <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>llh<span class="token punctuation">,</span>prior<span class="token punctuation">)</span>normalised_posterior <span class="token operator">=</span> posterior<span class="token operator">/</span>posterior<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>mu_values<span class="token punctuation">,</span> prior<span class="token punctuation">,</span><span class="token string">'b*'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'prior'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>mu_values<span class="token punctuation">,</span>normalised_posterior<span class="token punctuation">,</span><span class="token string">'r+'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'posterior'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'$\mu$'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">'falsecoin.pdf'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果先验分布是一个合适的概率分布函数，它应该归一化为:1.0</p><p><img src="/.io//unfaircoin1.png"><br><img src="/.io//unfaircoinw.jpg"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/02/13/hello-world/"/>
      <url>/2023/02/13/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
